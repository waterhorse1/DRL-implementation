{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN implementation by fxd\n",
    "#using atari games as a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DQN implementation by waterhorse\n",
    "#based on MorvanZhou's reinforcement code\n",
    "#using atari games as a test\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.set_random_seed(3)\n",
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        actions_n,\n",
    "        features_n,\n",
    "        learning_rate,\n",
    "        batch_size,\n",
    "        lamda,\n",
    "        start_epsilon,\n",
    "        final_epsilon\n",
    "        replace_iter,\n",
    "        memory_size,\n",
    "    ):\n",
    "        self.actions = actions_n#dimension for action space\n",
    "        self.features_n =features_n#size for the input image \n",
    "        self.lr = rate\n",
    "        self.start_epsilon = start_epsilon\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.epsilon = start_epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.lamda = lamda#decay\n",
    "        self.replace = replace_iter\n",
    "        self.__build__network()\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.memory=[]\n",
    "        self.memory_size = memory_size\n",
    "        self.memory_counter = 0\n",
    "        self.episode = 0\n",
    "        \n",
    "        target_net_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target_net')\n",
    "        evaluate_net_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='eval_net')\n",
    "\n",
    "        with tf.variable_scope('hard_replacement'):\n",
    "            self.target_replace_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]\n",
    "        \n",
    "        \n",
    "        self.train_episode = 0#record \n",
    "        tf.summary.FileWriter(\"./log/\",sess.graph)\n",
    "        \n",
    "        \n",
    "    def _build_net_all(self):\n",
    "        with tf.variable_scope('evaluate_network'):\n",
    "            self.s = tf.placeholder(tf.float32,[None,64,64,4],name=\"state\")\n",
    "            self.a = tf.placeholder(tf.int32,[None,],name=\"action\")\n",
    "            self.r = tf.placeholder(tf.float32,[None,],name=\"reward\")\n",
    "            self.done = tf.placeholder(tf.int32,[None,],name=\"done\")\n",
    "            self.size = tf.shape(self.a)[0]#size of batch\n",
    "            self.eval=self.build_net(s)\n",
    "            \n",
    "        with tf.variable_scope('target_network'):\n",
    "            self.s_ = tf.placeholder(tf.float32,[None,64,64,4],name=\"state\")\n",
    "            self.target = self.build_net(s_)\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            tar = tf.cond(self.done < 0.5,lambda:self.r + self.lamda*tf.reduce_max(self.target,axis = 1),\n",
    "                         lambda:self.r)\n",
    "            q_tar = tf.stop_gradient(tar)\n",
    "            index = tf.stack([tf.range(1,self.size,dtype=tf.int32),self.a],axis=1)\n",
    "            q_eval = tf.gather_nd(self.eval,index)\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.q_tar, self.q_eval, name='TD'))\n",
    "                                       \n",
    "        with tf.variable_scope('train'):\n",
    "            self._train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "            \n",
    "    def build_net(self,s): \n",
    "        W_conv1 = weight_variable([8, 8, 4, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "\n",
    "        W_conv2 = weight_variable([4, 4, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "\n",
    "        W_conv3 = weight_variable([3, 3, 64, 64])\n",
    "        b_conv3 = bias_variable([64])\n",
    "        \n",
    "        h_conv1 = tf.nn.relu(conv2d(s, W_conv1, 4) + b_conv1)\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2, 2) + b_conv2)\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "        h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 1) + b_conv3)\n",
    "        h_pool3 = max_pool_2x2(h_conv3)\n",
    "        \n",
    "        flat = tf.reshape(h_pool3,[self.size,-1])\n",
    "        \n",
    "        l1 = tf.layers.dense(flat,256,tf.nn.relu)\n",
    "        l2 = tf.layers.dense(l1,64,tf.nn.relu)\n",
    "        l3 = tf.layers.dense(l2,self.actions)\n",
    "        \n",
    "        return l3\n",
    "                                    \n",
    "        \n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev = 0.01)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.constant(0.01, shape = shape)\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv2d(x, W, stride):\n",
    "        return tf.nn.conv2d(x, W, strides = [1, stride, stride, 1], padding = \"SAME\")\n",
    "\n",
    "    def max_pool_2x2(x):\n",
    "        return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "                                       \n",
    "    def choose_action(self,s1):\n",
    "        s1 = s1[np.newaxis,:]\n",
    "        if(np.random.rand()>self.epsilon):\n",
    "            action = np.random.randint(0,self.actions)\n",
    "        else:\n",
    "            action = self.sess.run(self.eval,feed_dict={self.s:s1})\n",
    "            action = np.argmax(action)\n",
    "        return action\n",
    "                                           \n",
    "    def save_net(self,name):\n",
    "        self.saver.save(self.sess, \"model/\"+name)\n",
    "        \n",
    "    def load_net(self):\n",
    "        load = tf.train.import_meta_graph('model/my-model-290.meta')\n",
    "        load.restore(self.sess, tf.train.latest_checkpoint(\"model/\"))\n",
    "        \n",
    "    def learn(self):\n",
    "        if(self.episode%self.replace == 0):\n",
    "            self.episode = 0\n",
    "            self.sess.run(self.target_replace_op)\n",
    "            print('replace target_network params')\n",
    "            \n",
    "        minibatch = random.sample(self.memory,self.batch_size)\n",
    "        _ = self.sess.run([self._train_op],\n",
    "                          feed_dict=\n",
    "                          {\n",
    "                            self.s : [d[0] for d in minibatch]\n",
    "                            self.a : [d[1] for d in minibatch]\n",
    "                            self.r : [d[2] for d in minibatch]\n",
    "                            self.s_ : [d[3] for d in minibatch]\n",
    "                            self.done : [d[4] for d in minibatch]\n",
    "                          }\n",
    "                         )\n",
    "        self.episode += 1\n",
    "        \n",
    "        if(self.epsilon < self.final_epsilon):\n",
    "            self.epsilon += (self.start_epsilon -self.final_epsilon) / 150000\n",
    "        else:\n",
    "            self.epsilon = self.final_epsilon\n",
    "            \n",
    "    def store(self,s,a,r,s_,done):\n",
    "        if done:\n",
    "            done = 1\n",
    "        else:\n",
    "            done = 0\n",
    "            \n",
    "        mem = [s,a,r,s_,done]\n",
    "        if self.memory_size > len(self.memory):\n",
    "            self.memory_size.append(mem)\n",
    "        else:\n",
    "            self.memory_counter = self.memory_counter % self.memory_size\n",
    "            self.memory[self.memory_counter] = mem\n",
    "        self.memory_counter +=1\n",
    "        \n",
    "                                       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
